---
title: "Homework 2"
author: "Suning Zhao"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

### Load Libraries

```{r load_libraries}
library(tidyverse)
library(readxl)
library(lubridate)
```


### Problem 1 (The same as solution)

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c"))%>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct()
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

### Problem 2

###### Read and clean the data in the Mr.Trash Wheel sheet:

Below is the process to read and clean the data in the first sheet of 'Trash Wheel Collection Data.xlsx`, which is Mr.Trash Wheel:

* The process begins with data import and updating variable names. Within the `read_excel` function, I choose the range within A2:N549, to omit non-data entries.
* Then, I Use `drop_na` function to omit rows that do not include dumpster-specific data.
* In the next step, I round the number of sports balls to the nearest integer and converts the result to an integer variable using `as.integer`.Also, I convert `year` to numeric variable. In addition, I create a new variable `Trash_wheel` and define them as "Mr.Trash wheel". These is for merging purpose.

```{r}

Mr_Trash_wheel = 
  read_excel("./data/Trash Wheel Collection Data.xlsx",sheet = 1, range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
      sports_balls = as.integer(sports_balls),
      Trash_wheel = "Mr. Trash wheel",
      year = as.numeric(year)
    )
  Mr_Trash_wheel 
```

###### Read and clean the data in the Professor Wheel sheet:

Below is the process to read and clean the data in the second sheet of 'Trash Wheel Collection Data.xlsx`, which is Professor Wheel:

* The process begins with data import and updating variable names. Within the `read_excel` function, I choose the range within A2:M96, to omit non-data entries.
* Then, I Use `drop_na` function to omit rows that do not include dumpster-specific data.
* In the next step, I create a new variable `Trash_wheel` and define them as "Professor Trash wheel". These is for merging purpose.

```{r}
Pro_Trash_wheel = 
  read_excel("./data/Trash Wheel Collection Data.xlsx",sheet = 2, range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
      Trash_wheel = "Professor Trash wheel"
    )
  Pro_Trash_wheel
```

###### Merge three datasets use `full_join()`

Combine two trash wheel sheet. Since there is a huge difference between two dataset, we will choose full join method. After merging, I use `select()` to make the `dumpster` and `Trash_wheel` variables as top two columns.

```{r}
Trash_wheel =
  full_join(Mr_Trash_wheel, Pro_Trash_wheel) %>% 
  select(dumpster, Trash_wheel, everything())
  Trash_wheel
```

###### Calculate some important data and results:
```{r}
Trash_wheel %>% 
  select(dumpster, Trash_wheel) %>% 
  distinct

  summary(Trash_wheel)
  
Total_weight_pf = 
  filter(Trash_wheel, Trash_wheel == "Professor Trash wheel") %>%
  pull(weight_tons)%>%
  sum()

Total_sports_balls_Mr =
  filter(Trash_wheel, Trash_wheel == "Mr. Trash wheel", year == 2020) %>% 
  pull(sports_balls) %>% 
  sum()
```
* In the final merged dataset `Trash_wheel`, there are `r nrow(Trash_wheel)` observations and `r ncol(Trash_wheel)` variables. 
* The key variables' names are `r names(Trash_wheel)`
* The total weight of trash collected by Professor Trash Wheel is `r Total_weight_pf`
* The total number of sports balls collected by Mr. Trash Wheel is `r Total_sports_balls_Mr`

### Problem 3

###### Read and clean the data in pols-month.csv

Below is the process to read and clean the data in `pols-month.csv`:

* The process begins with data import and updating variable names.
* Then, I Use `separate()` to break up the variable `mon` into integer variables `year`,`month`, and `day`.
* In the next `mutate()` step, I use `month.abb` to replace month number with abbreviated month name and create a `president` variable taking values `gop` and `dem` using `recode()`.
* In `select()` step, I remove `prez_dem` and `prez_gop` and `day` variable and choose other variables.

```{r}
pols_month = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv")%>%
  janitor::clean_names() %>% 
  separate(col = mon, into = c('year','month','day'), sep = "-" , convert = TRUE) %>% 
  mutate(
     month = month.abb[month],
     president = recode(prez_dem, '0' = "gop", '1' = "dem")
  ) %>% 
  select(year, month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem)
pols_month
```

###### Read and clean the data in snp.csv

Below is the process to read and clean the data in `snp.csv`:

* The process begins with data import and updating variable names.
* Then, I Use `parse_date_time2()` in `lubridate()` to convert the date format to yyyy-mm-dd. This step is used for a uniform format of `month` variable for future merge.
* After converting the date format, I use `separate()` to break up the variable `mon` into integer variables `year`,`month`, and `day`.
* In the next `mutate()` step, I use `month.abb` to replace month number with abbreviated month name.
* In `select()` step, I only keep `year` and `month` and `close` variables, with `year` and `month` as leading columns and use `arrange()` step to arrange the order according to year and month.
```{r}
snp= 
  read_csv("./data/fivethirtyeight_datasets/snp.csv")%>% 
  janitor::clean_names() %>% 
  mutate(
     date_new = parse_date_time2(date, orders="mdy", cutoff_2000 = 23)
  ) %>%
  separate(col = date_new, into = c('year','month','day'), sep = "-" , convert = TRUE) %>% 
  mutate(
     month = month.abb[month]
  ) %>%   
  select(year, month, close) %>% 
  arrange(year, month)
snp
```

###### Read and clean the data in unemployment.csv

Below is the process to read and clean the data in `unemployment.csv`:

* The process begins with data import and updating variable names.
* Then, I Use `pivot_longer()` to switch the table from "wide" to "long" format, Making the original columns as `month`, and the values to `unemployment_rate`.
* After switching the table, I use `str_to_title()` to make the words in `month` as "Jan". This is to make sure we can combine three datasets.

```{r}
unemployment= 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv")%>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>% 
  mutate(
     month = str_to_title(month)
  ) 
unemployment
```

###### Merge three datasets use `left_join()`

```{r}
Five_Thirty_Eight =
  left_join(pols_month, snp, by = c("year","month")) %>% 
  left_join(unemployment, by = c("year","month"))
  Five_Thirty_Eight
```

###### Calculate some important data and results:
```{r}
# Describe pols_month
head(pols_month)
summary(pols_month)

# Describe snp
head(snp)
summary(snp)

# Describe unemployment
head(unemployment)
summary(unemployment)

# Describe Five_Thirty_Eight
head(Five_Thirty_Eight)
summary(Five_Thirty_Eight)
```

* The dataset `pols_month` contains `r nrow(pols_month)` observations and `r ncol(pols_month)` with the names `r names(pols_month)`. The year ranges from `r pols_month %>% pull(year) %>% range()`.

* The dataset `snp` contains `r nrow(snp)` observations and `r ncol(snp)` with the names `r names(snp)`. The year ranges from `r snp %>% pull(year) %>% range()`.

* The dataset `unemployment` contains `r nrow(unemployment)` observations and `r ncol(unemployment)` with the names `r names(unemployment)`. The year ranges from `r unemployment %>% pull(year) %>% range()`.

* The merged dataset `Five_Thirty_Eight`, which is a merged dataset of three datasets above, contains `r nrow(Five_Thirty_Eight)` observations and `r ncol(Five_Thirty_Eight)` with the names `r names(Five_Thirty_Eight)`. The year ranges from `r Five_Thirty_Eight %>% pull(year) %>% range()`.